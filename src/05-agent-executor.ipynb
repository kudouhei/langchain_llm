{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ff6379c1-4614-4049-82f9-da97e414ef57",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.tools import Tool\n",
    "\n",
    "# Define a tool\n",
    "def search_tool(query: str) -> str:\n",
    "    return f\"Search results for: {query}\"\n",
    "\n",
    "tools = [\n",
    "    Tool(\n",
    "        name=\"Search\",\n",
    "        func=search_tool,\n",
    "        description=\"Useful for searching the web or answering questions about current events.\"\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dbf69f9b-f743-4b36-89a3-1f35550b7913",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"input\", \"chat_history\", \"agent_scratchpad\"],\n",
    "    template=\"\"\"\n",
    "    You are a helpful assistant. Use tools when necessary to answer the following question:\n",
    "    Input: {input}\n",
    "    Chat History: {chat_history}\n",
    "    Agent Scratchpad: {agent_scratchpad}\n",
    "    \"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5a6cce8a-15db-4dc8-a1f1-3f3482e332cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data = {\n",
    "    \"input\": \"What is 10+10?\",\n",
    "    \"chat_history\": [],\n",
    "    \"agent_scratchpad\": \"\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c8ed8818-59be-490d-b1eb-80e0bac4ece7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama.chat_models import ChatOllama\n",
    "\n",
    "model_name = \"llama3.2:1b-instruct-fp16\"\n",
    "\n",
    "# initialize one LLM with temperature 0.0, this makes the LLM more deterministic\n",
    "llm = ChatOllama(temperature=0.0, model=model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "12e76b7f-e003-41b9-9396-e76c9d7a154a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "# Define the agent pipeline\n",
    "agent = (\n",
    "    {\n",
    "        \"input\": lambda x: x[\"input\"],\n",
    "        \"chat_history\": lambda x: x[\"chat_history\"],\n",
    "        \"agent_scratchpad\": lambda x: x.get(\"agent_scratchpad\", \"\")\n",
    "    }\n",
    "    | prompt\n",
    "    | llm\n",
    ")\n",
    "\n",
    "# Run the agent\n",
    "response = agent.invoke(input_data)\n",
    "print(response.tool_calls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "85f97ead-3be7-4c04-8def-2eb424febff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# bound_llm = llm.bind_tools(tools, tool_choice=\"Search\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40e1c817-1509-40d4-897d-9a612de5e09c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import initialize_agent\n",
    "from langchain.tools import Tool\n",
    "from langchain_ollama.chat_models import ChatOllama\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "\n",
    "model_name = \"llama3.2:1b-instruct-fp16\"\n",
    "\n",
    "# Define a tool\n",
    "def search_tool(query: str) -> str:\n",
    "    return f\"Search results for: {query}\"\n",
    "\n",
    "tools = [\n",
    "    Tool(\n",
    "        name=\"Search\",\n",
    "        func=search_tool,\n",
    "        description=\"Useful for searching the web or answering questions about current events.\"\n",
    "    )\n",
    "]\n",
    "\n",
    "# Initialize the LLM\n",
    "llm = ChatOllama(temperature=0.0, model=model_name)\n",
    "\n",
    "# Initialize memory\n",
    "memory = ConversationBufferMemory()\n",
    "\n",
    "# Create the agent with memory\n",
    "agent = initialize_agent(\n",
    "    tools,  # List of tools\n",
    "    llm,  # Language model\n",
    "    agent=\"zero-shot-react-description\",  # Agent type\n",
    "    verbose=True,  # Show detailed logs\n",
    "    memory=memory,  # Add memory\n",
    "    handle_parsing_errors=True  # Handle parsing errors\n",
    ")\n",
    "\n",
    "# Prepare input data\n",
    "input_data = {\n",
    "    \"input\": \"What is 10+10?\",\n",
    "    \"chat_history\": memory.buffer  # Include chat history from memory\n",
    "}\n",
    "\n",
    "# Run the agent\n",
    "response = agent.invoke(input_data)\n",
    "print(response)\n",
    "\n",
    "# Add the current interaction to memory\n",
    "memory.save_context(\n",
    "    {\"input\": input_data[\"input\"]},\n",
    "    {\"output\": response[\"output\"]}\n",
    ")\n",
    "\n",
    "# Follow-up input\n",
    "input_data = {\n",
    "    \"input\": \"Can you explain it in more detail?\",\n",
    "    \"chat_history\": memory.buffer  # Updated chat history\n",
    "}\n",
    "\n",
    "# Run the agent again\n",
    "response = agent.invoke(input_data)\n",
    "print(response)\n",
    "\n",
    "# Add the follow-up interaction to memory\n",
    "memory.save_context(\n",
    "    {\"input\": input_data[\"input\"]},\n",
    "    {\"output\": response[\"output\"]}\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
