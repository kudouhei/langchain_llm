{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9be442a8-065a-4156-ac4b-60f0aea41960",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !ollama pull llama3.2:1b-instruct-fp16\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3d35c7a9-86bf-476e-9055-9f78aacc8f8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import os\n",
    "import json\n",
    "import re\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "45e6a5a0-ce79-4e0e-a856-c4d8267eb87c",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv(override=True)\n",
    "api_key = os.getenv('OPENAI_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2178a9b7-6db1-408e-94c9-1cc01838ab46",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.tools import tool\n",
    "\n",
    "\n",
    "# The @tool decorator from langchain_core.tools to define custom tools in LangChain.\n",
    "\n",
    "@tool\n",
    "def add(x: float, y: float) -> float:\n",
    "    \"\"\"Add 'x' and 'y'. Both 'x' and 'y' are numbers.\"\"\"\n",
    "    return x + y\n",
    "\n",
    "@tool\n",
    "def multiply(x: float, y: float) -> float:\n",
    "    \"\"\"Multiply 'x' and 'y'. Both 'x' and 'y' are numbers.\"\"\"\n",
    "    return x * y\n",
    "\n",
    "@tool\n",
    "def exponentiate(x: float, y: float) -> float:\n",
    "    \"\"\"Raise 'x' to the power of 'y'. Both 'x' and 'y' are numbers.\"\"\"\n",
    "    return x ** y\n",
    "\n",
    "@tool\n",
    "def subtract(x: float, y: float) -> float:\n",
    "    \"\"\"Subtract 'x' from 'y'. Both 'x' and 'y' are numbers.\"\"\"\n",
    "    return y - x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1557852-5558-4f4e-8607-ed5d3d2d27d5",
   "metadata": {},
   "source": [
    "With the @tool decorator our function is turned into a StructuredTool object, which we can see below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5c470586-5a31-4aa7-a473-41b3901ebc5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StructuredTool(name='add', description=\"Add 'x' and 'y'. Both 'x' and 'y' are numbers.\", args_schema=<class 'langchain_core.utils.pydantic.add'>, func=<function add at 0x1077c7c40>)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "add"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "065d6966-3887-4f18-b924-ac1cefd9e4f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "add.name='add'\n",
      "add.description=\"Add 'x' and 'y'. Both 'x' and 'y' are numbers.\"\n"
     ]
    }
   ],
   "source": [
    "print(f\"{add.name=}\\n{add.description=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "96f050c3-c0ed-470d-ae95-517dec15a25e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'description': \"Add 'x' and 'y'. Both 'x' and 'y' are numbers.\",\n",
       " 'properties': {'x': {'title': 'X', 'type': 'number'},\n",
       "  'y': {'title': 'Y', 'type': 'number'}},\n",
       " 'required': ['x', 'y'],\n",
       " 'title': 'add',\n",
       " 'type': 'object'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The args_schema attribute in LangChain tools allows you to define a more structured schema for the arguments that the tool accepts. \n",
    "\n",
    "add.args_schema.model_json_schema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "26e89452-5159-4c5f-88ba-d9f4494e8abf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'description': \"Raise 'x' to the power of 'y'. Both 'x' and 'y' are numbers.\",\n",
       " 'properties': {'x': {'title': 'X', 'type': 'number'},\n",
       "  'y': {'title': 'Y', 'type': 'number'}},\n",
       " 'required': ['x', 'y'],\n",
       " 'title': 'exponentiate',\n",
       " 'type': 'object'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exponentiate.args_schema.model_json_schema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "34c62415-5d8c-4220-9b65-5f2785359001",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'x': 5, 'y': 2}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "llm_output_string = \"{\\\"x\\\": 5, \\\"y\\\": 2}\"\n",
    "llm_output_dict = json.loads(llm_output_string)  # load as dictionary\n",
    "llm_output_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4a0b4de5-ce0f-4c3d-a311-e7d2f4f957fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exponentiate.func(**llm_output_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "865501d2-4af4-4a5e-ae56-d0e6dad8dcc9",
   "metadata": {},
   "source": [
    "### Create an Agent\n",
    "\n",
    "LangChain Epression Language (LCEL) to construct the agent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "43c9c420-bf24-4ca7-9fc8-42bc261a5487",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (3950850003.py, line 2)",
     "output_type": "error",
     "traceback": [
      "  \u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31m<input parameters, including chat history and user query>\u001b[39m\n    ^\n\u001b[31mSyntaxError\u001b[39m\u001b[31m:\u001b[39m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "agent = (\n",
    "    <input parameters, including chat history and user query>\n",
    "    | <prompt>\n",
    "    | <LLM with tools>\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54e6613b-e4eb-4a48-ace6-62381fd4d600",
   "metadata": {},
   "source": [
    "**MessagesPlaceholder** is a placeholder in a prompt template that reserves space for a list of Message objects. These Message objects typically represent the conversation history or other dynamic content that will be inserted into the prompt at runtime."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3e1cc4e7-1d82-4e6b-ac3d-c8cceb2041a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "\n",
    "# prompt = ChatPromptTemplate.from_messages([\n",
    "#     (\"system\", (\n",
    "#         \"You're a helpful assistant. Using the tools provided you must answer the \"\n",
    "#         \"user's questions. To use the tool you must always provide the correct JSON \"\n",
    "#         \"format for the tool input. For example, if adding two numbers you would use \"\n",
    "#         \"the `add` tool, passing the two numbers to the `x` and `y` parameters.\"\n",
    "#     )),\n",
    "#     MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "#     (\"human\", \"{input}\"),\n",
    "#     (\"placeholder\", \"{agent_scratchpad}\"),\n",
    "# ])\n",
    "\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", (\n",
    "        \"You're a helpful assistant. When answering a user's question \"\n",
    "        \"you should first use one of the tools provided. After using a \"\n",
    "        \"tool the tool output will be provided in the \"\n",
    "        \"'scratchpad' below. If you have an answer in the \"\n",
    "        \"scratchpad you should not use any more tools and \"\n",
    "        \"instead answer directly to the user.\"\n",
    "    )),\n",
    "    MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "    (\"human\", \"{input}\"),\n",
    "    (\"ai\", \"Scratchpad: {agent_scratchpad}\"),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a976f654-c324-4b1e-8a6e-7ea694dc0f63",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# !pip install langchain\n",
    "# !pip install langchain-core\n",
    "\n",
    "# !pip install langchain-community\n",
    "\n",
    "# !pip install langchain_ollama\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3cf102d4-938d-4abe-9c72-05d418ec7985",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama.chat_models import ChatOllama\n",
    "\n",
    "model_name = \"llama3.2:1b-instruct-fp16\"\n",
    "\n",
    "# initialize one LLM with temperature 0.0, this makes the LLM more deterministic\n",
    "llm = ChatOllama(temperature=0.0, model=model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c249108f",
   "metadata": {},
   "source": [
    "When creating an agent we need to add conversational memory to make the agent remember previous interactions. We'll be using the older ConversationBufferMemory class rather than the newer RunnableWithMessageHistory â€” the reason being that we will also be using the older create_tool_calling_agent and AgentExecutor method and class.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2f36a8cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/hb/_y2tps0n0m77ytw9p5xk3kx41dbrb_/T/ipykernel_66088/287820297.py:3: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
      "  memory = ConversationBufferMemory(\n"
     ]
    }
   ],
   "source": [
    "from langchain.memory import ConversationBufferMemory\n",
    "\n",
    "memory = ConversationBufferMemory(\n",
    "    memory_key=\"chat_history\",  # must align with MessagesPlaceholder variable_name\n",
    "    return_messages=True  # to return Message objects\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32351aee",
   "metadata": {},
   "source": [
    "Initialize the agent\n",
    "\n",
    "- llm: as already defined\n",
    "- tools: to be defined (just a list of our previously defined tools)\n",
    "- prompt: as already defined\n",
    "- memory: as already defined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2e834ee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import create_tool_calling_agent\n",
    "\n",
    "tools = [add, multiply, exponentiate, subtract]\n",
    "\n",
    "agent = create_tool_calling_agent(\n",
    "    llm,\n",
    "    tools,\n",
    "    prompt,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c3a1cc18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install colab-xterm\n",
    "\n",
    "# !ollama serve &\n",
    "\n",
    "# !ollama pull llama3.2:1b-instruct-fp16\n",
    "\n",
    "# !curl http://127.0.0.1:11434\n",
    "\n",
    "# !ollama list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6f12497e-f3eb-4804-8ffb-fce8647861aa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AgentFinish(return_values={'output': ''}, log='')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.invoke({\n",
    "    \"input\": \"what is 10 multiplied by 7?\",\n",
    "    \"chat_history\": memory.chat_memory.messages,\n",
    "    \"intermediate_steps\": []  # agent will append it's internal steps here\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "de4b1543-2c82-4d36-9941-df039e422d26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We use the AgentExecutor class to handle the execution loop:\n",
    "\n",
    "from langchain.agents import AgentExecutor\n",
    "\n",
    "agent_executor = AgentExecutor(\n",
    "    agent=agent,\n",
    "    tools=tools,\n",
    "    memory=memory,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1f53a710-d2d4-44ea-9d22-fb80001d2807",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'what is 10 multiplied by 7?',\n",
       " 'chat_history': [HumanMessage(content='what is 10 multiplied by 7?', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content='', additional_kwargs={}, response_metadata={})],\n",
       " 'output': ''}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_executor.invoke({\n",
    "    \"input\": \"what is 10 multiplied by 7?\",\n",
    "    \"chat_history\": memory.chat_memory.messages,\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ef24e24e-d791-4627-9b89-7f7bf5d2a3dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'My name is Josh',\n",
       " 'chat_history': [HumanMessage(content='what is 10 multiplied by 7?', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content='', additional_kwargs={}, response_metadata={}),\n",
       "  HumanMessage(content='My name is Josh', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content='', additional_kwargs={}, response_metadata={})],\n",
       " 'output': ''}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_executor.invoke({\n",
    "    \"input\": \"My name is Josh\",\n",
    "    \"chat_history\": memory\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e505e195-4756-4098-b533-43700259d586",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-493"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "9+10-(4*2)**3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "975946b1-d195-4e33-b3ed-0d4bee4aaa18",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'What is my name',\n",
       " 'chat_history': [HumanMessage(content='what is 10 multiplied by 7?', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content='', additional_kwargs={}, response_metadata={}),\n",
       "  HumanMessage(content='My name is Josh', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content='', additional_kwargs={}, response_metadata={}),\n",
       "  HumanMessage(content='What is my name', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content='', additional_kwargs={}, response_metadata={})],\n",
       " 'output': ''}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_executor.invoke({\n",
    "    \"input\": \"What is my name\",\n",
    "    \"chat_history\": memory\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4490ae6d-8e01-483e-ba8c-6d3c23e04141",
   "metadata": {},
   "source": [
    "### SerpAPI Weather Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "688e3c64-56dc-4362-8acf-722396038d66",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"SERPAPI_API_KEY\"] = os.getenv(\"SERPAPI_API_KEY\") \\\n",
    "    or getpass(\"Enter your SerpAPI API key: \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "e8646cec-83b1-4256-81fe-c365489aaa36",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import load_tools\n",
    "\n",
    "toolbox = load_tools(tool_names=['serpapi'], llm=llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "1da595a5-2dc9-4703-8a8d-f5a6bfa56972",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from datetime import datetime\n",
    "\n",
    "@tool\n",
    "def get_location_from_ip():\n",
    "    \"\"\"Get the geographical location based on the IP address.\"\"\"\n",
    "    try:\n",
    "        response = requests.get(\"https://ipinfo.io/json\")\n",
    "        data = response.json()\n",
    "        if 'loc' in data:\n",
    "            latitude, longitude = data['loc'].split(',')\n",
    "            data = (\n",
    "                f\"Latitude: {latitude},\\n\"\n",
    "                f\"Longitude: {longitude},\\n\"\n",
    "                f\"City: {data.get('city', 'N/A')},\\n\"\n",
    "                f\"Country: {data.get('country', 'N/A')}\"\n",
    "            )\n",
    "            return data\n",
    "        else:\n",
    "            return \"Location could not be determined.\"\n",
    "    except Exception as e:\n",
    "        return f\"Error occurred: {e}\"\n",
    "    \n",
    "@tool\n",
    "def get_current_datetime() -> str:\n",
    "    \"\"\"Return the current date and time.\"\"\"\n",
    "    return datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "70a1ad36-0206-4c31-b738-b6f64ab9f87b",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"you're a helpful assistant\"),\n",
    "    (\"human\", \"{input}\"),\n",
    "    (\"placeholder\", \"{agent_scratchpad}\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "c428a867-9d27-4bbb-8c72-5f2faeccdd6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = toolbox + [get_current_datetime, get_location_from_ip]\n",
    "\n",
    "agent = create_tool_calling_agent(\n",
    "    llm=llm, tools=tools, prompt=prompt\n",
    ")\n",
    "\n",
    "agent_executor = AgentExecutor(\n",
    "    agent=agent, tools=tools, verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "f851c5f3-f51a-4831-86ee-6306b43012ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `get_current_datetime` with `London`\n",
      "\n",
      "\n",
      "\u001b[32;1m\u001b[1;3mThe current date and time in London is Wednesday, March 8th, 2023, 20:43:31 UTC (Coordinated Universal Time). \n",
      "\n",
      "As for the weather, I'm a large language model, I don't have real-time access to current weather conditions. However, I can suggest some ways for you to find out the current weather in London.\n",
      "\n",
      "You can check the weather forecast for London on websites like AccuWeather, Weather.com, or the Met Office (the UK's national weather service). These websites provide up-to-date weather forecasts and conditions for various locations around the world, including London.\n",
      "\n",
      "Alternatively, you can also download a weather app on your smartphone to get the current weather conditions in London. Some popular weather apps include Dark Sky, Weather Underground, and The Weather Channel.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "out = agent_executor.invoke({\n",
    "    \"input\": (\n",
    "        \"I have a few questions, what is the date and time in London right now? \"\n",
    "        \"How is the weather where I am? Please give me the degrees in Celsius\"\n",
    "    )\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "07bfa340-06c0-4dae-9f66-6b63be58414d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "The current date and time in London is Wednesday, March 8th, 2023, 20:43:31 UTC (Coordinated Universal Time). \n",
       "\n",
       "As for the weather, I'm a large language model, I don't have real-time access to current weather conditions. However, I can suggest some ways for you to find out the current weather in London.\n",
       "\n",
       "You can check the weather forecast for London on websites like AccuWeather, Weather.com, or the Met Office (the UK's national weather service). These websites provide up-to-date weather forecasts and conditions for various locations around the world, including London.\n",
       "\n",
       "Alternatively, you can also download a weather app on your smartphone to get the current weather conditions in London. Some popular weather apps include Dark Sky, Weather Underground, and The Weather Channel."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, Markdown\n",
    "\n",
    "display(Markdown(out[\"output\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f658be9-f23a-41aa-9400-0eddd761bba1",
   "metadata": {},
   "source": [
    "## LangChain Agent Executor\n",
    "\n",
    "Reason + Action (ReAct) agents use iterative reasoning and action steps to incorporate chain-of-thought and tool-use into their execution. During the reasoning step the LLM generates what steps to take to answer the query. Next, the LLM generates the action input, which our code logic parses into a tool call."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57c807b5-b72c-4973-9564-654b3ae8ae87",
   "metadata": {},
   "source": [
    "To add tools to our LLM, we will use the bind_tools method within the LCEL constructor, which will take our tools and add them to the LLM. We'll also include the tool_choice=\"any\" argument to bind_tools, which tells the LLM that it MUST use a tool, ie it cannot provide a final answer directly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b8e971d0-ead3-4ae0-9926-df9b5a75de71",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.tools import tool\n",
    "\n",
    "@tool\n",
    "def add(x: float, y: float) -> float:\n",
    "    \"\"\"Add 'x' and 'y'.\"\"\"\n",
    "    return x + y\n",
    "\n",
    "# Define the multiply tool\n",
    "@tool\n",
    "def multiply(x: float, y: float) -> float:\n",
    "    \"\"\"Multiply 'x' and 'y'.\"\"\"\n",
    "    return x * y\n",
    "\n",
    "# Define the exponentiate tool\n",
    "@tool\n",
    "def exponentiate(x: float, y: float) -> float:\n",
    "    \"\"\"Raise 'x' to the power of 'y'.\"\"\"\n",
    "    return x ** y\n",
    "\n",
    "@tool\n",
    "def subtract(x: float, y: float) -> float:\n",
    "    \"\"\"Subtract 'x' from 'y'.\"\"\"\n",
    "    return y - x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b5e71ae6-4353-4bd9-be24-bad9b21db1b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StructuredTool(name='add', description=\"Add 'x' and 'y'.\", args_schema=<class 'langchain_core.utils.pydantic.add'>, func=<function add at 0x123263240>)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "add"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a1ed7fb4-6b52-4720-83cb-3c2cffb41bee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "add.name='add'\n",
      "add.description=\"Add 'x' and 'y'.\"\n"
     ]
    }
   ],
   "source": [
    "print(f\"{add.name=}\\n{add.description=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2664aec0-7484-48e3-9ccf-f4de28241b9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'description': \"Add 'x' and 'y'.\",\n",
       " 'properties': {'x': {'title': 'X', 'type': 'number'},\n",
       "  'y': {'title': 'Y', 'type': 'number'}},\n",
       " 'required': ['x', 'y'],\n",
       " 'title': 'add',\n",
       " 'type': 'object'}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "add.args_schema.model_json_schema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "abcc0e6f-2be0-4469-b78d-06679d1a06aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'description': \"Raise 'x' to the power of 'y'.\",\n",
       " 'properties': {'x': {'title': 'X', 'type': 'number'},\n",
       "  'y': {'title': 'Y', 'type': 'number'}},\n",
       " 'required': ['x', 'y'],\n",
       " 'title': 'exponentiate',\n",
       " 'type': 'object'}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exponentiate.args_schema.model_json_schema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "36f3f447-b892-4335-8873-eaaae9f53844",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'x': 5, 'y': 2}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "llm_output_string = \"{\\\"x\\\": 5, \\\"y\\\": 2}\"  # this is the output from the LLM\n",
    "llm_output_dict = json.loads(llm_output_string)  # load as dictionary\n",
    "llm_output_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "dc4bd14d-4ac7-467e-bb7e-970495fbb27a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exponentiate.func(**llm_output_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7d249418-8f7a-4749-b64a-96cc938b18dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", (\n",
    "        \"You're a helpful assistant. When answering a user's question \"\n",
    "        \"you should first use one of the tools provided. After using a \"\n",
    "        \"tool the tool output will be provided in the \"\n",
    "        \"'scratchpad' below. If you have an answer in the \"\n",
    "        \"scratchpad you should not use any more tools and \"\n",
    "        \"instead answer directly to the user.\"\n",
    "    )),\n",
    "    MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "    (\"human\", \"{input}\"),\n",
    "    (\"ai\", \"Scratchpad: {agent_scratchpad}\"),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "882d5241-ceb2-4483-b2ef-247008d3b955",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama.chat_models import ChatOllama\n",
    "\n",
    "model_name = \"llama3.2:1b-instruct-fp16\"\n",
    "\n",
    "# initialize one LLM with temperature 0.0, this makes the LLM more deterministic\n",
    "llm = ChatOllama(temperature=0.0, model=model_name)\n",
    "bound_llm = llm.bind_tools(tools, tool_choice=\"any\")\n",
    "\n",
    "# llm\n",
    "# bound_llm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "afe4566f-0e73-4493-afc0-adcb76872115",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.tools import Tool\n",
    "\n",
    "# Define a tool\n",
    "def search_tool(query: str) -> str:\n",
    "    return f\"Search results for: {query}\"\n",
    "\n",
    "tools = [\n",
    "    Tool(\n",
    "        name=\"Search\",\n",
    "        func=search_tool,\n",
    "        description=\"Useful for searching the web or answering questions about current events.\"\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ece1da34-2e51-4188-b644-05963b0d0b2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\n",
       "  input: RunnableLambda(...),\n",
       "  chat_history: RunnableLambda(...),\n",
       "  agent_scratchpad: RunnableLambda(...)\n",
       "}\n",
       "| ChatPromptTemplate(input_variables=['agent_scratchpad', 'chat_history', 'input'], input_types={'chat_history': list[typing.Annotated[typing.Union[typing.Annotated[langchain_core.messages.ai.AIMessage, Tag(tag='ai')], typing.Annotated[langchain_core.messages.human.HumanMessage, Tag(tag='human')], typing.Annotated[langchain_core.messages.chat.ChatMessage, Tag(tag='chat')], typing.Annotated[langchain_core.messages.system.SystemMessage, Tag(tag='system')], typing.Annotated[langchain_core.messages.function.FunctionMessage, Tag(tag='function')], typing.Annotated[langchain_core.messages.tool.ToolMessage, Tag(tag='tool')], typing.Annotated[langchain_core.messages.ai.AIMessageChunk, Tag(tag='AIMessageChunk')], typing.Annotated[langchain_core.messages.human.HumanMessageChunk, Tag(tag='HumanMessageChunk')], typing.Annotated[langchain_core.messages.chat.ChatMessageChunk, Tag(tag='ChatMessageChunk')], typing.Annotated[langchain_core.messages.system.SystemMessageChunk, Tag(tag='SystemMessageChunk')], typing.Annotated[langchain_core.messages.function.FunctionMessageChunk, Tag(tag='FunctionMessageChunk')], typing.Annotated[langchain_core.messages.tool.ToolMessageChunk, Tag(tag='ToolMessageChunk')]], FieldInfo(annotation=NoneType, required=True, discriminator=Discriminator(discriminator=<function _get_type at 0x116a5d9e0>, custom_error_type=None, custom_error_message=None, custom_error_context=None))]]}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template=\"You're a helpful assistant. When answering a user's question you should first use one of the tools provided. After using a tool the tool output will be provided in the 'scratchpad' below. If you have an answer in the scratchpad you should not use any more tools and instead answer directly to the user.\"), additional_kwargs={}), MessagesPlaceholder(variable_name='chat_history'), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={}), AIMessagePromptTemplate(prompt=PromptTemplate(input_variables=['agent_scratchpad'], input_types={}, partial_variables={}, template='Scratchpad: {agent_scratchpad}'), additional_kwargs={})])\n",
       "| RunnableBinding(bound=ChatOllama(model='llama3.2:1b-instruct-fp16', temperature=0.0), kwargs={'tools': [{'type': 'function', 'function': {'name': 'add', 'description': \"Add 'x' and 'y'. Both 'x' and 'y' are numbers.\", 'parameters': {'properties': {'x': {'type': 'number'}, 'y': {'type': 'number'}}, 'required': ['x', 'y'], 'type': 'object'}}}, {'type': 'function', 'function': {'name': 'multiply', 'description': \"Multiply 'x' and 'y'. Both 'x' and 'y' are numbers.\", 'parameters': {'properties': {'x': {'type': 'number'}, 'y': {'type': 'number'}}, 'required': ['x', 'y'], 'type': 'object'}}}, {'type': 'function', 'function': {'name': 'exponentiate', 'description': \"Raise 'x' to the power of 'y'. Both 'x' and 'y' are numbers.\", 'parameters': {'properties': {'x': {'type': 'number'}, 'y': {'type': 'number'}}, 'required': ['x', 'y'], 'type': 'object'}}}, {'type': 'function', 'function': {'name': 'subtract', 'description': \"Subtract 'x' from 'y'. Both 'x' and 'y' are numbers.\", 'parameters': {'properties': {'x': {'type': 'number'}, 'y': {'type': 'number'}}, 'required': ['x', 'y'], 'type': 'object'}}}]}, config={}, config_factories=[])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.runnables.base import RunnableSerializable\n",
    "\n",
    "# tools = [add, subtract, multiply, exponentiate]\n",
    "\n",
    "# print(tools)\n",
    "\n",
    "# define the agent runnable\n",
    "agent: RunnableSerializable = (\n",
    "    {\n",
    "        \"input\": lambda x: x[\"input\"],\n",
    "        \"chat_history\": lambda x: x[\"chat_history\"],\n",
    "        \"agent_scratchpad\": lambda x: x.get(\"agent_scratchpad\", \"\")\n",
    "    }\n",
    "    | prompt\n",
    "    | bound_llm\n",
    ")\n",
    "\n",
    "# agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "177549c4-24be-4061-994f-ad93b36cf6c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='20', additional_kwargs={}, response_metadata={'model': 'llama3.2:1b-instruct-fp16', 'created_at': '2025-03-08T21:11:34.224951Z', 'done': True, 'done_reason': 'stop', 'total_duration': 152542584, 'load_duration': 29312250, 'prompt_eval_count': 132, 'prompt_eval_duration': 112000000, 'eval_count': 2, 'eval_duration': 10000000, 'message': Message(role='assistant', content='20', images=None, tool_calls=None)}, id='run-57acfcc2-e6cd-4602-951c-e48923320c44-0', usage_metadata={'input_tokens': 132, 'output_tokens': 2, 'total_tokens': 134})"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_data = {\n",
    "    \"input\": \"What is 10+10?\",\n",
    "    \"chat_history\": [],\n",
    "    \"agent_scratchpad\": \"\"\n",
    "}\n",
    "\n",
    "out = agent.invoke(input_data)\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "915e969c-9e27-48d1-b3ea-a46738bb5359",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.tool_calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "030f09de-6497-4c1c-ad38-7660b317ba4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create tool name to function mapping\n",
    "name2tool = {tool.name: tool.func for tool in tools}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9068b2e2-e8c4-4f66-9f8b-aac16c837129",
   "metadata": {},
   "outputs": [],
   "source": [
    "tool_output = name2tool[out.tool_calls[0][\"name\"]](**out.tool_calls[0][\"args\"])\n",
    "tool_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be09695e-8499-4501-a77c-737f8745a29c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
